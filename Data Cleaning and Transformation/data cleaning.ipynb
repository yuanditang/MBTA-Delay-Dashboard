{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf1c22d-7bba-4ed1-bc1e-09e198d870d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (13,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (13,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (13,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (13,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (13,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (13,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3200449878.py:22: DtypeWarning: Columns (16,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)  # 读取 CSV 文件\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         alert_id          cause   cause_detail        effect effect_detail  \\\n",
      "0          338650  UNKNOWN_CAUSE  UNKNOWN_CAUSE  OTHER_EFFECT  TRACK_CHANGE   \n",
      "1          338650  UNKNOWN_CAUSE  UNKNOWN_CAUSE  OTHER_EFFECT  TRACK_CHANGE   \n",
      "2          338650  UNKNOWN_CAUSE  UNKNOWN_CAUSE  OTHER_EFFECT  TRACK_CHANGE   \n",
      "3          338650  UNKNOWN_CAUSE  UNKNOWN_CAUSE  OTHER_EFFECT  TRACK_CHANGE   \n",
      "4          338650  UNKNOWN_CAUSE  UNKNOWN_CAUSE  OTHER_EFFECT  TRACK_CHANGE   \n",
      "...           ...            ...            ...           ...           ...   \n",
      "1890032    507845  UNKNOWN_CAUSE  UNKNOWN_CAUSE  OTHER_EFFECT         DELAY   \n",
      "1890033    507846    OTHER_CAUSE        TRAFFIC  OTHER_EFFECT         DELAY   \n",
      "1890034    507848  UNKNOWN_CAUSE  UNKNOWN_CAUSE  OTHER_EFFECT         DELAY   \n",
      "1890035    507848  UNKNOWN_CAUSE  UNKNOWN_CAUSE  OTHER_EFFECT         DELAY   \n",
      "1890036    507849    OTHER_CAUSE        TRAFFIC  OTHER_EFFECT         DELAY   \n",
      "\n",
      "        severity_level  severity  \\\n",
      "0                 INFO         1   \n",
      "1                 INFO         1   \n",
      "2                 INFO         1   \n",
      "3                 INFO         1   \n",
      "4                 INFO         1   \n",
      "...                ...       ...   \n",
      "1890032         SEVERE         6   \n",
      "1890033         SEVERE         6   \n",
      "1890034        WARNING         5   \n",
      "1890035        WARNING         5   \n",
      "1890036        WARNING         5   \n",
      "\n",
      "                                                    header  \\\n",
      "0        Please board all peak inbound Worcester Line t...   \n",
      "1        Please board all peak inbound Worcester Line t...   \n",
      "2        Please board all peak inbound Worcester Line t...   \n",
      "3        Please board all peak inbound Worcester Line t...   \n",
      "4        Please board all peak inbound Worcester Line t...   \n",
      "...                                                    ...   \n",
      "1890032   Route 57 experiencing delays of up to 25 minutes   \n",
      "1890033  Route 110 experiencing delays of up to 25 minu...   \n",
      "1890034   Route 32 experiencing delays of up to 20 minutes   \n",
      "1890035   Route 32 experiencing delays of up to 20 minutes   \n",
      "1890036  Route 28 experiencing delays of up to 20 minut...   \n",
      "\n",
      "                                               description   alert_lifecycle  \\\n",
      "0        Please follow these boarding instructions Mond...  UPCOMING_ONGOING   \n",
      "1        Please follow these boarding instructions Mond...  UPCOMING_ONGOING   \n",
      "2        Please follow these boarding instructions Mond...  UPCOMING_ONGOING   \n",
      "3        Please follow these boarding instructions Mond...  UPCOMING_ONGOING   \n",
      "4        Please follow these boarding instructions Mond...  UPCOMING_ONGOING   \n",
      "...                                                    ...               ...   \n",
      "1890032                                                NaN               NEW   \n",
      "1890033                                                NaN               NEW   \n",
      "1890034                                                NaN               NEW   \n",
      "1890035                                                NaN               NEW   \n",
      "1890036                                                NaN               NEW   \n",
      "\n",
      "         ... active_period_start_date active_period_start_dt  \\\n",
      "0        ...               2020-11-02   2020-11-02T15:50:00Z   \n",
      "1        ...               2020-11-02   2020-11-02T15:50:00Z   \n",
      "2        ...               2020-11-02   2020-11-02T15:50:00Z   \n",
      "3        ...               2020-11-02   2020-11-02T15:50:00Z   \n",
      "4        ...               2020-11-02   2020-11-02T15:50:00Z   \n",
      "...      ...                      ...                    ...   \n",
      "1890032  ...               2023-06-30   2023-06-30T23:26:29Z   \n",
      "1890033  ...               2023-06-30   2023-06-30T23:55:44Z   \n",
      "1890034  ...               2023-06-30   2023-06-30T23:59:20Z   \n",
      "1890035  ...               2023-06-30   2023-06-30T23:59:20Z   \n",
      "1890036  ...               2023-06-30   2023-06-30T23:59:49Z   \n",
      "\n",
      "         active_period_end_dt last_push_notification_dt      route_id  \\\n",
      "0        2020-11-02T20:00:00Z                       NaN  CR-Worcester   \n",
      "1        2020-11-02T20:00:00Z                       NaN  CR-Worcester   \n",
      "2        2020-11-02T20:00:00Z                       NaN  CR-Worcester   \n",
      "3        2020-11-02T20:00:00Z                       NaN  CR-Worcester   \n",
      "4        2020-11-02T20:00:00Z                       NaN  CR-Worcester   \n",
      "...                       ...                       ...           ...   \n",
      "1890032  2023-07-01T01:26:37Z      2023-06-30T23:26:30Z            57   \n",
      "1890033  2023-07-01T01:56:37Z      2023-06-30T23:55:45Z           110   \n",
      "1890034  2023-07-01T01:59:37Z      2023-06-30T23:59:21Z            32   \n",
      "1890035  2023-07-01T01:59:37Z      2023-06-30T23:59:21Z          3233   \n",
      "1890036  2023-07-01T02:00:37Z      2023-06-30T23:59:50Z            28   \n",
      "\n",
      "        route_type direction_id           stop_id facility_id       activities  \n",
      "0              2.0          NaN       West Natick         NaN            BOARD  \n",
      "1              2.0          NaN  Wellesley Square         NaN            BOARD  \n",
      "2              2.0          NaN   Wellesley Hills         NaN            BOARD  \n",
      "3              2.0          NaN   Wellesley Farms         NaN            BOARD  \n",
      "4              2.0          NaN     Natick Center         NaN            BOARD  \n",
      "...            ...          ...               ...         ...              ...  \n",
      "1890032        3.0          NaN               NaN         NaN  BOARD|EXIT|RIDE  \n",
      "1890033        3.0          NaN               NaN         NaN  BOARD|EXIT|RIDE  \n",
      "1890034        3.0          NaN               NaN         NaN  BOARD|EXIT|RIDE  \n",
      "1890035        3.0          NaN               NaN         NaN  BOARD|EXIT|RIDE  \n",
      "1890036        3.0          NaN               NaN         NaN  BOARD|EXIT|RIDE  \n",
      "\n",
      "[1890037 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定主文件夹路径\n",
    "base_dir = \"Archive 2020-2023\"\n",
    "\n",
    "# 目标年份\n",
    "years_to_merge = [\"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "\n",
    "# 存储所有 DataFrame\n",
    "dfs = []\n",
    "\n",
    "# 遍历指定年份的文件夹\n",
    "for year in years_to_merge:\n",
    "    year_path = os.path.join(base_dir, year)\n",
    "    \n",
    "    if os.path.exists(year_path):\n",
    "        # 遍历该年份文件夹内的所有 CSV 文件\n",
    "        for file in os.listdir(year_path):\n",
    "            if file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(year_path, file)\n",
    "                df = pd.read_csv(file_path)  # 读取 CSV 文件\n",
    "                dfs.append(df)  # 添加到列表中\n",
    "\n",
    "# 合并所有 DataFrame\n",
    "if dfs:\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    # 打印合并后的数据\n",
    "    print(merged_df)\n",
    "else:\n",
    "    print(\"未找到任何 CSV 文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da683f6e-50fb-418b-9b16-d8107d74bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3412671004.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  delay_df['created_dt'] = pd.to_datetime(delay_df['created_dt'])\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3412671004.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  delay_df['last_modified_dt'] = pd.to_datetime(delay_df['last_modified_dt'])\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3412671004.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  delay_df['delay_duration'] = (delay_df['last_modified_dt'] - delay_df['created_dt']).dt.total_seconds()\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3412671004.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  delay_df['year'] = delay_df['created_dt'].dt.year\n",
      "/var/folders/6k/6gh7mwnd44g1q3ngnf39sklh0000gn/T/ipykernel_9472/3412671004.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  delay_df['stop_id'] = delay_df['stop_id'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     route_id      stop_name  year  delay_duration\n",
      "0        Blue        Airport  2020        283428.0\n",
      "1        Blue        Airport  2021         36345.0\n",
      "2        Blue        Airport  2022       5729123.0\n",
      "3        Blue        Airport  2023         83922.0\n",
      "4        Blue       Aquarium  2020          1192.0\n",
      "...       ...            ...   ...             ...\n",
      "1026      Red  South Station  2023       1093320.0\n",
      "1027      Red      Wollaston  2020        293634.0\n",
      "1028      Red      Wollaston  2021        206976.0\n",
      "1029      Red      Wollaston  2022        528888.0\n",
      "1030      Red      Wollaston  2023        380991.0\n",
      "\n",
      "[1031 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设你的 DataFrame 已加载为 merged_df\n",
    "# 1. 筛选出包含 \"delay\" 的行，并且 route_id 在指定的路由 ID 列表中\n",
    "route_ids = [\"Green-B\", \"Green-C\", \"Green-D\", \"Green-E\", \"Red\", \"Blue\", \"Orange\", \"Mattapan\"]\n",
    "delay_df = merged_df[\n",
    "    merged_df['header'].str.contains('delay', case=False, na=False) &\n",
    "    merged_df['route_id'].isin(route_ids)\n",
    "]\n",
    "\n",
    "# 2. 将时间列转换为 datetime 格式\n",
    "delay_df['created_dt'] = pd.to_datetime(delay_df['created_dt'])\n",
    "delay_df['last_modified_dt'] = pd.to_datetime(delay_df['last_modified_dt'])\n",
    "\n",
    "# 3. 计算延迟时间\n",
    "delay_df['delay_duration'] = (delay_df['last_modified_dt'] - delay_df['created_dt']).dt.total_seconds()\n",
    "\n",
    "# 4. 添加 year 列，提取 created_dt 中的年份\n",
    "delay_df['year'] = delay_df['created_dt'].dt.year\n",
    "\n",
    "# 5. 加载 MBTA_Rapid_Transit_Stop_Distances.csv 文件\n",
    "stop_distances_df = pd.read_csv('MBTA_Rapid_Transit_Stop_Distances.csv')\n",
    "\n",
    "# 6. 获取 stop_name，通过 stop_id 和 from_stop_id 匹配\n",
    "stop_distances_df = stop_distances_df[['from_stop_id', 'from_stop_name']].rename(columns={'from_stop_id': 'stop_id', 'from_stop_name': 'stop_name'})\n",
    "\n",
    "# 7. 将 stop_id 列转换为字符串类型，以便于匹配\n",
    "delay_df['stop_id'] = delay_df['stop_id'].astype(str)\n",
    "stop_distances_df['stop_id'] = stop_distances_df['stop_id'].astype(str)\n",
    "\n",
    "# 8. 将 stop_name 添加到 delay_df 中，通过 stop_id 匹配\n",
    "delay_df = delay_df.merge(stop_distances_df, on='stop_id', how='left')\n",
    "\n",
    "# 9. 按照 route_id、stop_name 和 year 分组，计算每个组的延迟时间总和\n",
    "grouped_delay = delay_df.groupby(['route_id', 'stop_name', 'year'])['delay_duration'].sum().reset_index()\n",
    "\n",
    "# 10. 打印结果\n",
    "print(grouped_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de0fbc68-40ad-418f-baeb-3dbc78d7fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the grouped_delay DataFrame ready\n",
    "grouped_delay.to_csv('grouped_delay.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
